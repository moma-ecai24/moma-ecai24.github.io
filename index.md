---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
---

Problems with multiple objectives - in which agents must learn to reach diverse and potentially conflicting compromises - are ubiquitous in many real-world problems. Settings such as traffic congestion and healthcare coordination are naturally characterised by complex trade-offs that must be balanced according to some user utility. Moving from traditional single-objective optimization to a multi-objective perspective presents new challenges and opportunities that will be examined in this tutorial.
This tutorial is an exposition of foundational ideas,  challenges, and seminal work in multi-objective multi-agent decision-making. To that end, it is most closely aligned with the objectives of introducing expert non-specialists to an AI subarea, as well as with motivating and explaining a topic of emerging importance for AI.
The target audience for the tutorial is represented by researchers and students in AI, CS, or Mathematics. Some previous experience (however brief) in either game theory, planning, reinforcement learning, or utility theory is desirable but not required. We will provide a condensed overview of the fundamental models that will be used in this tutorial. 
Recent advancements in artificial intelligence pose opportunities to develop a multi-objective perspective in multi-agent systems that can facilitate collective decision-making and produce better tools for cooperation. Multi-objective techniques centred around balancing trade-offs arising from a user's utility can foster a human-centric approach to decision-making.

